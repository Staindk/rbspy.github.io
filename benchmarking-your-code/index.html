<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta property="og:title" content=" Benchmarking your code &middot;  rbspy docs" />
<meta property="og:site_name" content="rbspy docs" />
<meta property="og:url" content="https://rbspy.github.io/benchmarking-your-code/" />


    <meta property="og:type" content="article" />
    <meta property="og:article:published_time" content="0001-01-01T00:00:00Z" />
    

    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@" />
    <meta name="twitter:creator" content="@" />
    <meta name="twitter:title" content="Benchmarking your code" />
    <meta name="twitter:description" content="" />
    <meta name="twitter:url" content="https://rbspy.github.io/benchmarking-your-code/" />
    <meta name="twitter:image" content="https://rbspy.github.io/rbspy.jpg" />


<title> Benchmarking your code &middot;  rbspy docs</title>


    <meta name="description" content="" />


<meta name="p:domain_verify" content="fc173d84e3a4de948ed4bda2908afd3e"/>
<meta name="HandheldFriendly" content="True" />
<meta name="MobileOptimized" content="320" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />





<link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,700italic,300,700' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Bree+Serif' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://rbspy.github.io/css/pure-min.css">


    <link rel="stylesheet" href="https://rbspy.github.io/css/grids-responsive-min.css">

<link rel="stylesheet" href="https://rbspy.github.io/css/crisp.css">
<link rel="stylesheet" href="https://rbspy.github.io/css/rrssb.css">








<link rel="canonical" href="https://rbspy.github.io/benchmarking-your-code/" />


    


    </head>
    <body>
        <div id="layout" class="pure-g">
            <div class="sidebar pure-u-1 pure-u-md-1-6">
                <div class="header">
    <div class="title">
        <h1><a href="https://rbspy.github.io/">rbspy docs</a></h1>
        
        
    </div>
    <div class="logo">
        
        
            
                <a id="logo" href="https://rbspy.github.io/"><img src="https://rbspy.github.io/rbspy.jpg" alt="rbspy docs" /></a>
            
        
    </div>

    <div id="menuToggle">
    
    <input type="checkbox" />
    
    
    <span></span>
    <span></span>
    <span></span>
    
    <div id="menu">
        <ul class="sidebar-menu">
            
                <li class="sidebar-menu-item"><a href="https://rbspy.github.io/">Home</a></li>
            
                <li class="sidebar-menu-item"><a href="https://rbspy.github.io/installing/">Installing</a></li>
            
                <li class="sidebar-menu-item"><a href="https://rbspy.github.io/using-rbspy/">Using rbspy</a></li>
            
                <li class="sidebar-menu-item"><a href="https://rbspy.github.io/rbspy-vs-stackprof/">rbspy vs stackprof</a></li>
            
                <li class="sidebar-menu-item"><a href="https://rbspy.github.io/getting-help/">Getting help</a></li>
            
                <li class="sidebar-menu-item"><i class='fa fa-github fa-1x'></i> <a href="https://github.com/rbspy/rbspy">GitHub</a></li>
            
        </ul>
        <h3 class="menu-title">Profiling guide</h3>
        <ul class="sidebar-menu">
            
                <li class="sidebar-menu-item"><a href="https://rbspy.github.io/about-profiling-guide/">About the guide</a></li>
            
                <li class="sidebar-menu-item"><a href="https://rbspy.github.io/optimization-questions/">Questions to ask when optimizing</a></li>
            
                <li class="sidebar-menu-item"><a href="https://rbspy.github.io/benchmarking-your-code/">Benchmarking your code</a></li>
            
                <li class="sidebar-menu-item"><a href="https://rbspy.github.io/using-flamegraphs/">Using flamegraphs</a></li>
            
        </ul>
    </div>
    </div>

    <div id="follow-icons">
        
        
        
        
        
        
        
        
        
    </div>

    
</div>

            </div>
            <div class="content pure-u-1 pure-u-md-5-6">
                <div class="singlepage">
                    <div class="article" id="" class="page">
                        <div class="post-stamp">
                            <h1 class="post-title">Benchmarking your code</h1>
                        </div>
                        <aside>
                            <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#what-s-benchmarking-why-is-it-important">What&rsquo;s benchmarking? Why is it important?</a></li>
<li><a href="#run-your-benchmarks-more-than-once">Run your benchmarks more than once</a></li>
<li><a href="#using-benchmarking-profiling-to-make-your-code-faster">Using benchmarking + profiling to make your code faster</a>
<ul>
<li><a href="#technique-1-benchmark-locally">Technique 1: Benchmark locally</a></li>
<li><a href="#technique-2-monitor-production-performance">Technique 2: Monitor production performance</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
                        </aside>
                        

<p>People who are just getting started making their code faster sometimes confuse <strong>benchmarking</strong> and
<strong>profiling</strong>. Let&rsquo;s explain the difference and how to use both techniques to make your code faster!</p>

<p>In short: a benchmark tells you <strong>how slow</strong> your code is (&ldquo;it took 20 seconds to do X Y Z&rdquo;) and a
profiler tells you <strong>why it&rsquo;s slow</strong> (&ldquo;35% of that time was spent doing compression&rdquo;).</p>

<h2 id="what-s-benchmarking-why-is-it-important">What&rsquo;s benchmarking? Why is it important?</h2>

<p>Optimizing code is often very counterintuitive &ndash; often I&rsquo;ll have a great idea for how to make my
code faster, and it&rsquo;ll turn out to make almost no difference at all in practice. So when optimizing,
it&rsquo;s extremely important to have objective standards you can measure your changes against!</p>

<p>A <strong>benchmark</strong> is a test that you run to measure how fast your code is. For example, if I have a
compression library, I might test how long it takes to compress a given 100MB file. Or if I was
working on Jekyll&rsquo;s performance (a static site generator), I might take a specific large site and
benchmark how long Jekyll takes to render that site.</p>

<p>If you can run the benchmark on your dev machine, you can make changes, see &ldquo;oh, that didn&rsquo;t make
any difference!&ldquo;, and then quickly try out a different approach.</p>

<h2 id="run-your-benchmarks-more-than-once">Run your benchmarks more than once</h2>

<p>Suppose you run your benchmark and it takes 6 seconds. You make some optimizations and run it again,
and afterwards it takes 5.7 seconds. That&rsquo;s a 5% performance improvement, right? Not huge, but not
nothing?</p>

<p>Not necessarily!</p>

<p>Here&rsquo;s a real benchmark from my computer (generating a Jekyll site), and how long it took (in
seconds) across 10 different runs:</p>

<pre><code>5.94
6.00
6.04
5.98
6.15
6.37
6.14
6.20
5.98
6.18
6.22
6.04
6.16
</code></pre>

<p>When I ran it 100 times, there was even more variation &ndash; sometimes it would take up to 9 seconds
(for instance if I was using a lot of CPU).</p>

<p>So the same benchmark, on the same computer, can take anywhere between 6 to 9 seconds.
This means that if, for this benchmark, I see a performance improvement of less than 0.5 seconds
(~10%) or so, it&rsquo;s worth being suspicious.</p>

<p>We don&rsquo;t have time here to do a rigorous discussion of statistics and benchmarking, but here are a
few guidelines:</p>

<ul>
<li>be suspicious of small performance improvements (like 5% or 10%). The smaller the performance
improvement you&rsquo;re trying to verify, the more times you need to run your benchmark to be sure that
it&rsquo;s real.</li>
<li>running any benchmark 10 times instead of just once is a good way to get an idea of how much
natural variation that benchmark has.</li>
</ul>

<p>If you&rsquo;re interested in taking a more statistically rigorous approach, a good starting point is to
look up &ldquo;bootstrap confidence intervals&rdquo;, which is an easy computational way (very little math!) to
get confidence intervals.</p>

<h2 id="using-benchmarking-profiling-to-make-your-code-faster">Using benchmarking + profiling to make your code faster</h2>

<p>There are basically 2 typical workflows you can use when optimizing your code. Basically: you can
either profile a benchmark of your code, or you can profile your code running in production.</p>

<p>Both of these techniques are basically the same: measure your code&rsquo;s speed somehow, profile it, come
up with potentially faster code, and then measure again afterwards to see if it actually worked!</p>

<p>The most important tip here is: <strong>don&rsquo;t use profiler results to figure out if your optimization
worked, use benchmark results</strong>. Using benchmark results will help you make sure that your
optimization actually makes a significant improvement to the program&rsquo;s performance as a whole.</p>

<h3 id="technique-1-benchmark-locally">Technique 1: Benchmark locally</h3>

<ol>
<li>Realize something is slow (&ldquo;oh no, this computation is taking SO LONG, why??&rdquo;)</li>
<li>Create a <strong>benchmark</strong> that you can run locally that demonstrates the slow behavior. This doesn&rsquo;t
need to be complicated!</li>
<li>Run your benchmark (10 times!) to get a baseline for how long it takes</li>
<li>Profile the benchmark.</li>
<li>Implement a fix</li>
<li>Run your benchmark again to see if your fix worked!</li>
</ol>

<h3 id="technique-2-monitor-production-performance">Technique 2: Monitor production performance</h3>

<p>This technique has a little less of the scientific rigor that you get when you make a benchmark, but
often making a benchmark isn&rsquo;t practical! A lot of things happen in production that are hard to
reproduce, but you need to figure out why they&rsquo;re happening anyway.</p>

<ol>
<li>Realize something is slow (your users are complaining about performance!)</li>
<li>Find a way to monitor the slow thing in production with your favorite monitoring tool (graphite,
datadog, new relic, whatever)</li>
<li>Profile the code running in production</li>
<li>Implement a fix and deploy it to a test environment or to production</li>
<li>Use your monitoring to see if the performance improved!</li>
</ol>

                        
                        
    <div id="comments">
        
        
    </div>


                    </div>
                </div>
                


            </div>
        </div>
    </body>
</html>
